# è¯­éŸ³å”¤é†’æœåŠ¡å™¨éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨ GPU äº‘æœåŠ¡å™¨ä¸Šéƒ¨ç½²å…¨åŠŸèƒ½è¯­éŸ³å¤„ç†æœåŠ¡ï¼ŒåŒ…å«ï¼š
- è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰- è¯­éŸ³è½¬æ–‡å­—
- å£°çº¹è¯†åˆ« - è¯†åˆ«/éªŒè¯è¯´è¯äºº
- è¯­éŸ³å¢žå¼º - é™å™ªã€åŽ»æ··å“
- æƒ…æ„Ÿè¯†åˆ« - è¯†åˆ«è¯­éŸ³æƒ…ç»ª
- è¯­è¨€è¯†åˆ« - è¯†åˆ«è¯´çš„ä»€ä¹ˆè¯­è¨€
- VAD - æ£€æµ‹æ˜¯å¦æœ‰äººè¯´è¯
- TTS - æ–‡å­—è½¬è¯­éŸ³

---

## æœåŠ¡å™¨ä¿¡æ¯

```
IP: 117.50.176.26
ç«¯å£: 23
ç”¨æˆ·: root
å¯†ç : Wsq7Se4vLmi96HT

è¿žæŽ¥å‘½ä»¤: ssh -p 23 root@117.50.176.26
```

---

## ç¬¬ä¸€æ­¥ï¼šè¿žæŽ¥æœåŠ¡å™¨

### æ–¹å¼ä¸€ï¼šå‘½ä»¤è¡Œ
```bash
ssh -p 23 root@117.50.176.26
# è¾“å…¥å¯†ç : Wsq7Se4vLmi96HT
```

### æ–¹å¼äºŒï¼šVS Code Remote-SSH
1. å®‰è£… Remote-SSH æ’ä»¶
2. é…ç½® `~/.ssh/config`:
```
Host gpu-server
    HostName 117.50.176.26
    User root
    Port 23
```
3. è¿žæŽ¥ gpu-server

---

## ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥çŽ¯å¢ƒ

```bash
# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ Python
python --version

# æ£€æŸ¥ CUDA
nvcc --version
```

---

## ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºé¡¹ç›®ç›®å½•

```bash
mkdir -p /root/voice-wake-server
cd /root/voice-wake-server
```

---

## ç¬¬å››æ­¥ï¼šå®‰è£…æ‰€æœ‰ä¾èµ–

```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£… PyTorchï¼ˆCUDA 12.x ç‰ˆæœ¬ï¼‰
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# ============ æ ¸å¿ƒæ¨¡å— ============

# Whisper - è¯­éŸ³è¯†åˆ«ï¼ˆä¸­æ–‡æ•ˆæžœæœ€å¥½ï¼‰
pip install openai-whisper

# Faster-Whisper - åŠ é€Ÿç‰ˆè¯­éŸ³è¯†åˆ«ï¼ˆæŽ¨èï¼Œé€Ÿåº¦å¿« 2-4 å€ï¼‰
pip install faster-whisper

# SpeechBrain - å£°çº¹è¯†åˆ«ã€è¯­éŸ³å¢žå¼ºã€æƒ…æ„Ÿè¯†åˆ«ç­‰
pip install speechbrain

# ============ è¾…åŠ©æ¨¡å— ============

# è¯­è¨€è¯†åˆ«
pip install langid

# ============ Web æœåŠ¡ ============

# FastAPI Web æ¡†æž¶
pip install fastapi uvicorn websockets python-multipart

# å…¶ä»–å·¥å…·
pip install numpy scipy librosa soundfile
```

### ä¸€é”®å®‰è£…å‘½ä»¤

```bash
pip install --upgrade pip && \
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121 && \
pip install openai-whisper faster-whisper speechbrain langid && \
pip install fastapi uvicorn websockets python-multipart numpy scipy librosa soundfile
```

---

## ç¬¬äº”æ­¥ï¼šåˆ›å»ºæœåŠ¡ç«¯ä»£ç 

```bash
cat > /root/voice-wake-server/server.py << 'EOF'
"""
è¯­éŸ³å”¤é†’æœåŠ¡å™¨
åŠŸèƒ½ï¼šWhisper è¯­éŸ³è¯†åˆ« + SpeechBrain å£°çº¹è¯†åˆ« + å”¤é†’è¯æ£€æµ‹
"""

import torch
import numpy as np
import logging
from typing import Optional, Dict, Any
from fastapi import FastAPI, WebSocket, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI(title="è¯­éŸ³å”¤é†’æœåŠ¡å™¨")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

models = {"whisper": None, "speaker": None}
user_configs: Dict[str, Dict[str, Any]] = {}

def get_user_config(user_id: str) -> Dict[str, Any]:
    if user_id not in user_configs:
        user_configs[user_id] = {"wake_word": "ä½ å¥½æ˜Ÿå¹´", "voice_embedding": None, "voice_enabled": False}
    return user_configs[user_id]

@app.on_event("startup")
async def load_models():
    global models
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # Faster-Whisper
    logger.info("åŠ è½½ Faster-Whisper...")
    try:
        from faster_whisper import WhisperModel
        models["whisper"] = WhisperModel("base", device=device, compute_type="float16")
        logger.info("âœ… Faster-Whisper åŠ è½½å®Œæˆ")
    except Exception as e:
        logger.warning(f"Faster-Whisper å¤±è´¥ï¼Œä½¿ç”¨åŽŸç‰ˆ: {e}")
        import whisper
        models["whisper"] = whisper.load_model("base", device=device)
    
    # å£°çº¹è¯†åˆ«
    logger.info("åŠ è½½å£°çº¹è¯†åˆ«æ¨¡åž‹...")
    try:
        from speechbrain.inference.speaker import SpeakerRecognition
        models["speaker"] = SpeakerRecognition.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="/root/voice-wake-server/models/speaker",
            run_opts={"device": device}
        )
        logger.info("âœ… å£°çº¹è¯†åˆ«åŠ è½½å®Œæˆ")
    except Exception as e:
        logger.error(f"å£°çº¹è¯†åˆ«åŠ è½½å¤±è´¥: {e}")
    
    logger.info("ðŸŽ‰ æœåŠ¡å°±ç»ªï¼")

def audio_bytes_to_numpy(audio_bytes: bytes) -> np.ndarray:
    return np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0

def transcribe_audio(audio_np: np.ndarray) -> dict:
    if models["whisper"] is None:
        return {"text": "", "error": "æ¨¡åž‹æœªåŠ è½½"}
    try:
        if hasattr(models["whisper"], 'transcribe'):
            segments, info = models["whisper"].transcribe(audio_np, language="zh", beam_size=5)
            text = "".join([seg.text for seg in segments])
            return {"text": text.strip()}
        else:
            result = models["whisper"].transcribe(audio_np, language="zh", fp16=True)
            return {"text": result["text"].strip()}
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
        return {"text": "", "error": str(e)}

def get_speaker_embedding(audio_np: np.ndarray) -> Optional[torch.Tensor]:
    if models["speaker"] is None:
        return None
    try:
        audio_tensor = torch.from_numpy(audio_np).unsqueeze(0)
        return models["speaker"].encode_batch(audio_tensor)
    except Exception as e:
        logger.error(f"å£°çº¹æå–é”™è¯¯: {e}")
        return None

def verify_speaker(emb1, emb2, threshold=0.5) -> dict:
    score = torch.nn.functional.cosine_similarity(emb1, emb2).item()
    return {"is_same": score > threshold, "score": score}

@app.get("/")
async def root():
    return {"status": "ok", "loaded_models": [k for k, v in models.items() if v]}

@app.post("/set_wake_word")
async def set_wake_word(user_id: str = Form(...), wake_word: str = Form(...)):
    config = get_user_config(user_id)
    config["wake_word"] = wake_word
    logger.info(f"ç”¨æˆ· {user_id} è®¾ç½®å”¤é†’è¯: {wake_word}")
    return {"status": "ok", "wake_word": wake_word}

@app.post("/register_voice")
async def register_voice(user_id: str = Form(...), audio: UploadFile = File(...)):
    config = get_user_config(user_id)
    audio_np = audio_bytes_to_numpy(await audio.read())
    embedding = get_speaker_embedding(audio_np)
    if embedding is not None:
        config["voice_embedding"] = embedding
        config["voice_enabled"] = True
        logger.info(f"ç”¨æˆ· {user_id} æ³¨å†Œå£°çº¹æˆåŠŸ")
        return {"status": "ok", "message": "å£°çº¹æ³¨å†ŒæˆåŠŸ"}
    raise HTTPException(status_code=500, detail="å£°çº¹æå–å¤±è´¥")

@app.post("/recognize")
async def recognize(user_id: str = Form(...), audio: UploadFile = File(...)):
    config = get_user_config(user_id)
    audio_np = audio_bytes_to_numpy(await audio.read())
    
    asr_result = transcribe_audio(audio_np)
    text = asr_result["text"]
    wake_detected = config["wake_word"] in text
    
    result = {"text": text, "wake_detected": wake_detected, "wake_word": config["wake_word"],
              "speaker_verified": False, "speaker_score": 0.0}
    
    if wake_detected and config["voice_enabled"] and config["voice_embedding"] is not None:
        emb = get_speaker_embedding(audio_np)
        if emb is not None:
            verify = verify_speaker(config["voice_embedding"], emb)
            result["speaker_verified"] = verify["is_same"]
            result["speaker_score"] = verify["score"]
    return result

@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    await websocket.accept()
    config = get_user_config(user_id)
    logger.info(f"ç”¨æˆ· {user_id} è¿žæŽ¥")
    try:
        while True:
            audio_np = audio_bytes_to_numpy(await websocket.receive_bytes())
            text = transcribe_audio(audio_np)["text"]
            wake_detected = config["wake_word"] in text
            
            result = {"text": text, "wake_detected": wake_detected, "speaker_verified": False, "speaker_score": 0.0}
            if wake_detected and config["voice_enabled"] and config["voice_embedding"] is not None:
                emb = get_speaker_embedding(audio_np)
                if emb:
                    verify = verify_speaker(config["voice_embedding"], emb)
                    result["speaker_verified"] = verify["is_same"]
                    result["speaker_score"] = verify["score"]
            
            await websocket.send_json(result)
            if wake_detected:
                logger.info(f"ðŸŽ¤ ç”¨æˆ· {user_id} å”¤é†’: {text}")
    except Exception as e:
        logger.error(f"WebSocket é”™è¯¯: {e}")
    finally:
        logger.info(f"ç”¨æˆ· {user_id} æ–­å¼€")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
EOF
```

---

## ç¬¬å…­æ­¥ï¼šå¯åŠ¨æœåŠ¡

### æ–¹å¼ä¸€ï¼šå‰å°è¿è¡Œï¼ˆæµ‹è¯•ç”¨ï¼‰

```bash
cd /root/voice-wake-server
python server.py
```

### æ–¹å¼äºŒï¼šåŽå°è¿è¡Œ

```bash
cd /root/voice-wake-server
nohup python server.py > server.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f server.log

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep server.py

# åœæ­¢æœåŠ¡
pkill -f "python server.py"
```

### æ–¹å¼ä¸‰ï¼šsystemd å¼€æœºè‡ªå¯åŠ¨ï¼ˆæŽ¨èï¼‰

```bash
# åˆ›å»º systemd æœåŠ¡æ–‡ä»¶
cat > /etc/systemd/system/voice-wake.service << 'EOF'
[Unit]
Description=Voice Wake Server
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/voice-wake-server
ExecStart=/usr/bin/python /root/voice-wake-server/server.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

# é‡æ–°åŠ è½½ systemd
systemctl daemon-reload

# å¯åŠ¨æœåŠ¡
systemctl start voice-wake

# è®¾ç½®å¼€æœºè‡ªå¯åŠ¨
systemctl enable voice-wake

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
systemctl status voice-wake

# æŸ¥çœ‹æ—¥å¿—
journalctl -u voice-wake -f

# åœæ­¢æœåŠ¡
systemctl stop voice-wake

# é‡å¯æœåŠ¡
systemctl restart voice-wake
```

---

## ç¬¬ä¸ƒæ­¥ï¼šæµ‹è¯• API

### 1. å¥åº·æ£€æŸ¥

```
GET /
```

è¯·æ±‚ï¼š
```bash
curl http://localhost:8000/
```

å“åº”ï¼š
```json
{
    "status": "ok",
    "loaded_models": ["whisper", "speaker"]
}
```

---

### 2. è®¾ç½®å”¤é†’è¯

```
POST /set_wake_word
Content-Type: multipart/form-data
```

| å‚æ•° | ç±»åž‹ | å¿…å¡« | è¯´æ˜Ž |
|------|------|------|------|
| user_id | string | æ˜¯ | ç”¨æˆ·ID |
| wake_word | string | æ˜¯ | å”¤é†’è¯ |

è¯·æ±‚ï¼š
```bash
curl -X POST http://localhost:8000/set_wake_word \
  -F "user_id=user001" \
  -F "wake_word=ä½ å¥½æ˜Ÿå¹´"
```

å“åº”ï¼š
```json
{
    "status": "ok",
    "wake_word": "ä½ å¥½æ˜Ÿå¹´"
}
```

---

### 3. æ³¨å†Œå£°çº¹

```
POST /register_voice
Content-Type: multipart/form-data
```

| å‚æ•° | ç±»åž‹ | å¿…å¡« | è¯´æ˜Ž |
|------|------|------|------|
| user_id | string | æ˜¯ | ç”¨æˆ·ID |
| audio | file | æ˜¯ | éŸ³é¢‘æ–‡ä»¶ï¼ˆ16kHz, 16bit, mono, PCM/WAVï¼‰ |

è¯·æ±‚ï¼š
```bash
curl -X POST http://localhost:8000/register_voice \
  -F "user_id=user001" \
  -F "audio=@my_voice.wav"
```

å“åº”ï¼š
```json
{
    "status": "ok",
    "message": "å£°çº¹æ³¨å†ŒæˆåŠŸ"
}
```

---

### 4. è¯­éŸ³è¯†åˆ« + å”¤é†’è¯æ£€æµ‹

```
POST /recognize
Content-Type: multipart/form-data
```

| å‚æ•° | ç±»åž‹ | å¿…å¡« | è¯´æ˜Ž |
|------|------|------|------|
| user_id | string | æ˜¯ | ç”¨æˆ·ID |
| audio | file | æ˜¯ | éŸ³é¢‘æ–‡ä»¶ï¼ˆ16kHz, 16bit, mono, PCM/WAVï¼‰ |

è¯·æ±‚ï¼š
```bash
curl -X POST http://localhost:8000/recognize \
  -F "user_id=user001" \
  -F "audio=@test.wav"
```

å“åº”ï¼š
```json
{
    "text": "ä½ å¥½æ˜Ÿå¹´æ‰“å¼€ç¯",
    "wake_detected": true,
    "wake_word": "ä½ å¥½æ˜Ÿå¹´",
    "speaker_verified": true,
    "speaker_score": 0.85
}
```

| å“åº”å­—æ®µ | ç±»åž‹ | è¯´æ˜Ž |
|------|------|------|
| text | string | è¯†åˆ«å‡ºçš„æ–‡å­— |
| wake_detected | bool | æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯ |
| wake_word | string | å½“å‰è®¾ç½®çš„å”¤é†’è¯ |
| speaker_verified | bool | å£°çº¹æ˜¯å¦åŒ¹é…ï¼ˆéœ€å…ˆæ³¨å†Œå£°çº¹ï¼‰ |
| speaker_score | float | å£°çº¹ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šç›¸ä¼¼ï¼‰ |

---

### 5. WebSocket å®žæ—¶è¯­éŸ³è¯†åˆ«

```
WebSocket /ws/{user_id}
```

Python ç¤ºä¾‹ï¼š
```python
import asyncio
import websockets

async def test_ws():
    uri = "ws://localhost:8000/ws/user001"
    async with websockets.connect(uri) as ws:
        # å‘é€éŸ³é¢‘æ•°æ®ï¼ˆ16kHz, 16bit, mono, PCMï¼‰
        with open("test.raw", "rb") as f:
            audio_data = f.read()
        await ws.send(audio_data)
        
        # æŽ¥æ”¶ç»“æžœ
        result = await ws.recv()
        print(result)

asyncio.run(test_ws())
```

å“åº”ï¼š
```json
{
    "text": "ä½ å¥½æ˜Ÿå¹´",
    "wake_detected": true,
    "speaker_verified": false,
    "speaker_score": 0.0
}
```

---

## éŸ³é¢‘æ ¼å¼è¦æ±‚

| å‚æ•° | å€¼ |
|------|------|
| é‡‡æ ·çŽ‡ | 16000 Hz |
| ä½æ·±åº¦ | 16 bit |
| å£°é“ | å•å£°é“ (mono) |
| æ ¼å¼ | PCM æˆ– WAV |

---

## å…¬ç½‘è®¿é—®

ç¡®ä¿é˜²ç«å¢™å¼€æ”¾ 8000 ç«¯å£ï¼š

```bash
ufw allow 8000
```

è®¿é—®åœ°å€ï¼š`http://117.50.176.26:8000/`
